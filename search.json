[{"path":"https://atorus-research.github.io/datasetjson/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"Apache License","title":"Apache License","text":"Version 2.0, January 2004 <http://www.apache.org/licenses/>","code":""},{"path":[]},{"path":"https://atorus-research.github.io/datasetjson/LICENSE.html","id":"id_1-definitions","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"1. Definitions","title":"Apache License","text":"“License” shall mean terms conditions use, reproduction, distribution defined Sections 1 9 document. “Licensor” shall mean copyright owner entity authorized copyright owner granting License. “Legal Entity” shall mean union acting entity entities control, controlled , common control entity. purposes definition, “control” means () power, direct indirect, cause direction management entity, whether contract otherwise, (ii) ownership fifty percent (50%) outstanding shares, (iii) beneficial ownership entity. “” (“”) shall mean individual Legal Entity exercising permissions granted License. “Source” form shall mean preferred form making modifications, including limited software source code, documentation source, configuration files. “Object” form shall mean form resulting mechanical transformation translation Source form, including limited compiled object code, generated documentation, conversions media types. “Work” shall mean work authorship, whether Source Object form, made available License, indicated copyright notice included attached work (example provided Appendix ). “Derivative Works” shall mean work, whether Source Object form, based (derived ) Work editorial revisions, annotations, elaborations, modifications represent, whole, original work authorship. purposes License, Derivative Works shall include works remain separable , merely link (bind name) interfaces , Work Derivative Works thereof. “Contribution” shall mean work authorship, including original version Work modifications additions Work Derivative Works thereof, intentionally submitted Licensor inclusion Work copyright owner individual Legal Entity authorized submit behalf copyright owner. purposes definition, “submitted” means form electronic, verbal, written communication sent Licensor representatives, including limited communication electronic mailing lists, source code control systems, issue tracking systems managed , behalf , Licensor purpose discussing improving Work, excluding communication conspicuously marked otherwise designated writing copyright owner “Contribution.” “Contributor” shall mean Licensor individual Legal Entity behalf Contribution received Licensor subsequently incorporated within Work.","code":""},{"path":"https://atorus-research.github.io/datasetjson/LICENSE.html","id":"id_2-grant-of-copyright-license","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"2. Grant of Copyright License","title":"Apache License","text":"Subject terms conditions License, Contributor hereby grants perpetual, worldwide, non-exclusive, -charge, royalty-free, irrevocable copyright license reproduce, prepare Derivative Works , publicly display, publicly perform, sublicense, distribute Work Derivative Works Source Object form.","code":""},{"path":"https://atorus-research.github.io/datasetjson/LICENSE.html","id":"id_3-grant-of-patent-license","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"3. Grant of Patent License","title":"Apache License","text":"Subject terms conditions License, Contributor hereby grants perpetual, worldwide, non-exclusive, -charge, royalty-free, irrevocable (except stated section) patent license make, made, use, offer sell, sell, import, otherwise transfer Work, license applies patent claims licensable Contributor necessarily infringed Contribution(s) alone combination Contribution(s) Work Contribution(s) submitted. institute patent litigation entity (including cross-claim counterclaim lawsuit) alleging Work Contribution incorporated within Work constitutes direct contributory patent infringement, patent licenses granted License Work shall terminate date litigation filed.","code":""},{"path":"https://atorus-research.github.io/datasetjson/LICENSE.html","id":"id_4-redistribution","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"4. Redistribution","title":"Apache License","text":"may reproduce distribute copies Work Derivative Works thereof medium, without modifications, Source Object form, provided meet following conditions: () must give recipients Work Derivative Works copy License; (b) must cause modified files carry prominent notices stating changed files; (c) must retain, Source form Derivative Works distribute, copyright, patent, trademark, attribution notices Source form Work, excluding notices pertain part Derivative Works; (d) Work includes “NOTICE” text file part distribution, Derivative Works distribute must include readable copy attribution notices contained within NOTICE file, excluding notices pertain part Derivative Works, least one following places: within NOTICE text file distributed part Derivative Works; within Source form documentation, provided along Derivative Works; , within display generated Derivative Works, wherever third-party notices normally appear. contents NOTICE file informational purposes modify License. may add attribution notices within Derivative Works distribute, alongside addendum NOTICE text Work, provided additional attribution notices construed modifying License. may add copyright statement modifications may provide additional different license terms conditions use, reproduction, distribution modifications, Derivative Works whole, provided use, reproduction, distribution Work otherwise complies conditions stated License.","code":""},{"path":"https://atorus-research.github.io/datasetjson/LICENSE.html","id":"id_5-submission-of-contributions","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"5. Submission of Contributions","title":"Apache License","text":"Unless explicitly state otherwise, Contribution intentionally submitted inclusion Work Licensor shall terms conditions License, without additional terms conditions. Notwithstanding , nothing herein shall supersede modify terms separate license agreement may executed Licensor regarding Contributions.","code":""},{"path":"https://atorus-research.github.io/datasetjson/LICENSE.html","id":"id_6-trademarks","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"6. Trademarks","title":"Apache License","text":"License grant permission use trade names, trademarks, service marks, product names Licensor, except required reasonable customary use describing origin Work reproducing content NOTICE file.","code":""},{"path":"https://atorus-research.github.io/datasetjson/LICENSE.html","id":"id_7-disclaimer-of-warranty","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"7. Disclaimer of Warranty","title":"Apache License","text":"Unless required applicable law agreed writing, Licensor provides Work (Contributor provides Contributions) “” BASIS, WITHOUT WARRANTIES CONDITIONS KIND, either express implied, including, without limitation, warranties conditions TITLE, NON-INFRINGEMENT, MERCHANTABILITY, FITNESS PARTICULAR PURPOSE. solely responsible determining appropriateness using redistributing Work assume risks associated exercise permissions License.","code":""},{"path":"https://atorus-research.github.io/datasetjson/LICENSE.html","id":"id_8-limitation-of-liability","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"8. Limitation of Liability","title":"Apache License","text":"event legal theory, whether tort (including negligence), contract, otherwise, unless required applicable law (deliberate grossly negligent acts) agreed writing, shall Contributor liable damages, including direct, indirect, special, incidental, consequential damages character arising result License use inability use Work (including limited damages loss goodwill, work stoppage, computer failure malfunction, commercial damages losses), even Contributor advised possibility damages.","code":""},{"path":"https://atorus-research.github.io/datasetjson/LICENSE.html","id":"id_9-accepting-warranty-or-additional-liability","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"9. Accepting Warranty or Additional Liability","title":"Apache License","text":"redistributing Work Derivative Works thereof, may choose offer, charge fee , acceptance support, warranty, indemnity, liability obligations /rights consistent License. However, accepting obligations, may act behalf sole responsibility, behalf Contributor, agree indemnify, defend, hold Contributor harmless liability incurred , claims asserted , Contributor reason accepting warranty additional liability. END TERMS CONDITIONS","code":""},{"path":"https://atorus-research.github.io/datasetjson/LICENSE.html","id":"appendix-how-to-apply-the-apache-license-to-your-work","dir":"","previous_headings":"","what":"APPENDIX: How to apply the Apache License to your work","title":"Apache License","text":"apply Apache License work, attach following boilerplate notice, fields enclosed brackets [] replaced identifying information. (Don’t include brackets!) text enclosed appropriate comment syntax file format. also recommend file class name description purpose included “printed page” copyright notice easier identification within third-party archives.","code":"Copyright 2023 Atorus Research, Inc.  Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at    http://www.apache.org/licenses/LICENSE-2.0  Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."},{"path":"https://atorus-research.github.io/datasetjson/articles/converting_files.html","id":"converting-from-xpt","dir":"Articles","previous_headings":"","what":"Converting from XPT","title":"Converting from XPT","text":"Ideally ’re converting XPT file SAS7BDAT file, appropriate metadata maintained separate dataset . Inevitably information get lost exchanged differences information applied R interprets SAS datasets. one reason {datasetjson} improves upon XPTs exchange format. leiu external metadata, ’s example can make best effort conversion. Now metadata, can use write Dataset JSON file. Just good measure, can confirm metadata just created compliant schema.","code":"adsl <- haven::read_xpt(file.path(system.file(package='datasetjson'), \"adsl.xpt\"))  #' Gather variable metadata in Dataset JSON compliant format #' #' @param n Variable name #' @param .data Dataset to gather attributes #' #' @returns Columns compliant data frame extract_xpt_meta <- function(n, .data) {      attrs <- attributes(.data[[n]])      out <- list()    # Identify the variable type   if (inherits(.data[[n]],\"Date\")) {     out$dataType <- \"date\"     out$targetDataType <- \"integer\"   } else if (inherits(.data[[n]],\"POSIXt\")) {     out$dataType <- \"datetime\"     out$targetDataType <- \"integer\"   } else if (inherits(.data[[n]],\"numeric\")) {     if (any(is.double(.data[[n]]))) out$dataType <- \"float\"     else out$dataType <- \"integer\"   }  else if (inherits(.data[[n]],\"hms\")) {     out$dataType <- \"time\"     out$targetDataType <- \"integer\"   } else {     out$dataType <- \"string\"     out$length <- max(purrr::map_int(.data[[n]], nchar))   }      out$itemOID <- n   out$name <- n   out$label <- attr(.data[[n]], 'label')   out$displayFormat <- attr(.data[[n]], 'format.sas')   tibble::as_tibble(out)    }  # Loop the ADSL columns adsl_meta <- purrr::map_df(names(adsl), extract_xpt_meta, .data=adsl) adsl_meta #> # A tibble: 49 × 7 #>    dataType length itemOID name    label            targetDataType displayFormat #>    <chr>     <int> <chr>   <chr>   <chr>            <chr>          <chr>         #>  1 string       12 STUDYID STUDYID Study Identifier NA             NA            #>  2 string       11 USUBJID USUBJID Unique Subject … NA             NA            #>  3 string        4 SUBJID  SUBJID  Subject Identif… NA             NA            #>  4 string        3 SITEID  SITEID  Study Site Iden… NA             NA            #>  5 string        3 SITEGR1 SITEGR1 Pooled Site Gro… NA             NA            #>  6 string       20 ARM     ARM     Description of … NA             NA            #>  7 string       20 TRT01P  TRT01P  Planned Treatme… NA             NA            #>  8 float        NA TRT01PN TRT01PN Planned Treatme… NA             NA            #>  9 string       20 TRT01A  TRT01A  Actual Treatmen… NA             NA            #> 10 float        NA TRT01AN TRT01AN Actual Treatmen… NA             NA            #> # ℹ 39 more rows # Create the datasetjson object ds_json <- dataset_json(   adsl,    item_oid = \"ADSL\",   name = \"ADSL\",   dataset_label = attr(adsl, 'label'),   columns = adsl_meta )  # Write the JSON json_file_content <- write_dataset_json(ds_json) # Check schema compliance validate_dataset_json(json_file_content) #> File is valid per the Dataset JSON v1.1.0 schema #> [1] instancePath schemaPath   keyword      params       message      #> [6] schema       parentSchema dataPath     #> <0 rows> (or 0-length row.names)"},{"path":"https://atorus-research.github.io/datasetjson/articles/converting_files.html","id":"bulk-file-conversion","dir":"Articles","previous_headings":"","what":"Bulk File Conversion","title":"Converting from XPT","text":"intention convert files Dataset JSON format bulk, couple things consider - especially ’re trying replicate existing procedures done using SAS: Remember R default holds data memory, whereas work datasets SAS still written disk. means ’re bulk conversion datasets, ’ll want read write one dataset time. example: Read XPT SAS7BDAT file Write Dataset JSON file Remove objects memory free space ’s likely best wrap conversion process function, function namespace inherently release temporary objects garbage collection. Depending size data, easy max memory first read datasets. second consideration use function validate_dataset_json(). Particularly large datasets, recommend using function. validation performs Dataset JSON schema - ’s performing additional CDISC checks data. offer function primarily due fact schema available, necessary function allows check schema compliance met. said, ’ve done testing make sure write_dataset_json() writes file using compliant schema - step redundant.","code":""},{"path":"https://atorus-research.github.io/datasetjson/articles/datasetjson.html","id":"using-datasetjson","dir":"Articles","previous_headings":"","what":"Using datasetjson","title":"Getting Started","text":"datasetjson works allowing take data frame apply necessary attributes required CDISC Dataset JSON. goal make experience simple. can write Dataset JSON file disk, first need build Dataset JSON object. example call looks like : minimum information required provide create datasetjson object. parameters can described follows: input data frame iris item_oid, can described “Object Dataset”, key value unique identifier dataset, corresponding ItemGroupDef/@OID Define-XML. name, dataset name dataset_label, dataset label, finally columns, variable level metadata dataset. columns parameter special , provide data frame necessary variable metadata. Take look iris_items data frame. data frame 7 columns, 4 strictly required. defined CDISC Dataset JSON Specification. data within dataframe ultimately populates columns element Dataset JSON file. itemOID, name, label, dataType columns required must populated variable. Note dataType column list allowable values: string integer float double decimal boolean datetime date time URI information must provided directly user. Note type conversions data performed datasetjson package. displayFormat column inherently refers display formats used within SAS.","code":"ds_json <- dataset_json(head(iris, 5),                          item_oid = \"IG.IRIS\",                          name = \"IRIS\",                          dataset_label = \"Iris\",                          columns = iris_items) iris_items #>              itemOID         name          label dataType length keySequence #> 1 IT.IR.Sepal.Length Sepal.Length   Sepal Length    float     NA           2 #> 2  IT.IR.Sepal.Width  Sepal.Width    Sepal Width    float     NA          NA #> 3 IT.IR.Petal.Length Petal.Length   Petal Length    float     NA           3 #> 4  IT.IR.Petal.Width  Petal.Width    Petal Width    float     NA          NA #> 5      IT.IR.Species      Species Flower Species   string     10           1"},{"path":"https://atorus-research.github.io/datasetjson/articles/datasetjson.html","id":"writing-and-reading","dir":"Articles","previous_headings":"Using datasetjson","what":"Writing and Reading","title":"Getting Started","text":"datasetjson object allows collect information needed generate Dataset JSON file, write dataset need use write_dataset_json() file. Dataset JSON object available, need object name file path. write_dataset_json() also option return JSON output character string. Similarly, read Dataset JSON object, can use function read_dataset_json(). function return dataframe , ready use. read, provide file path. can also provide single element character vector JSON text already read . data frame ’s read datasetjson object carries number attributes. example, opening dataframe within RStudio IDE present variable labels. Additionally, extra metadata provided Dataset JSON file available. attributes provided follow naming convention Dataset JSON standard. ’ve provided helper functions leverage data . ’d like grab column metadata columns element, can use function get_column_metadata() column metadata available, can additionally use function set_variable_attributes() apply columns metadata individual variables within data frame.","code":"write_dataset_json(ds_json, file=\"iris.json\") js <- write_dataset_json(ds_json, pretty=TRUE) cat(js) #> { #>   \"datasetJSONCreationDateTime\": \"2025-01-31T17:25:14\", #>   \"datasetJSONVersion\": \"1.1.0\", #>   \"itemGroupOID\": \"IG.IRIS\", #>   \"records\": 5, #>   \"name\": \"IRIS\", #>   \"label\": \"Iris\", #>   \"columns\": [ #>     { #>       \"itemOID\": \"IT.IR.Sepal.Length\", #>       \"name\": \"Sepal.Length\", #>       \"label\": \"Sepal Length\", #>       \"dataType\": \"float\", #>       \"keySequence\": 2 #>     }, #>     { #>       \"itemOID\": \"IT.IR.Sepal.Width\", #>       \"name\": \"Sepal.Width\", #>       \"label\": \"Sepal Width\", #>       \"dataType\": \"float\" #>     }, #>     { #>       \"itemOID\": \"IT.IR.Petal.Length\", #>       \"name\": \"Petal.Length\", #>       \"label\": \"Petal Length\", #>       \"dataType\": \"float\", #>       \"keySequence\": 3 #>     }, #>     { #>       \"itemOID\": \"IT.IR.Petal.Width\", #>       \"name\": \"Petal.Width\", #>       \"label\": \"Petal Width\", #>       \"dataType\": \"float\" #>     }, #>     { #>       \"itemOID\": \"IT.IR.Species\", #>       \"name\": \"Species\", #>       \"label\": \"Flower Species\", #>       \"dataType\": \"string\", #>       \"length\": 10, #>       \"keySequence\": 1 #>     } #>   ], #>   \"rows\": [ #>     [ #>       5.1, #>       3.5, #>       1.4, #>       0.2, #>       \"setosa\" #>     ], #>     [ #>       4.9, #>       3.0, #>       1.4, #>       0.2, #>       \"setosa\" #>     ], #>     [ #>       4.7, #>       3.2, #>       1.3, #>       0.2, #>       \"setosa\" #>     ], #>     [ #>       4.6, #>       3.1, #>       1.5, #>       0.2, #>       \"setosa\" #>     ], #>     [ #>       5.0, #>       3.6, #>       1.4, #>       0.2, #>       \"setosa\" #>     ] #>   ] #> } read_dataset_json(\"path/to/file\") dat <- read_dataset_json(js) get_column_metadata(dat) #>              itemOID         name          label dataType keySequence #> 1 IT.IR.Sepal.Length Sepal.Length   Sepal Length    float           2 #> 2  IT.IR.Sepal.Width  Sepal.Width    Sepal Width    float          NA #> 3 IT.IR.Petal.Length Petal.Length   Petal Length    float           3 #> 4  IT.IR.Petal.Width  Petal.Width    Petal Width    float          NA #> 5      IT.IR.Species      Species Flower Species   string           1 #>   targetDataType length displayFormat #> 1           <NA>     NA          <NA> #> 2           <NA>     NA          <NA> #> 3           <NA>     NA          <NA> #> 4           <NA>     NA          <NA> #> 5           <NA>     10          <NA> dat <- set_variable_attributes(dat) attributes(dat$Species) #> $label #> [1] \"Flower Species\" #>  #> $itemOID #> [1] \"IT.IR.Species\" #>  #> $dataType #> [1] \"string\" #>  #> $keySequence #> [1] 1 #>  #> $length #> [1] 10"},{"path":"https://atorus-research.github.io/datasetjson/articles/date_time_datetime.html","id":"metadata-settings","dir":"Articles","previous_headings":"","what":"Metadata Settings","title":"Dates, Times, and Datetimes","text":"Version 5 SAS Transport Files didn’t notion “date”, “time” “datetime” type. Instead, using SAS convention just Integer values display format attached. Dataset JSON Version 1.1 explicitly clarifies numeric date types using dataType targetDataType fields columns metadata. Consider variables. table , metadata character numeric dates, times, date times. sets variables values within dataType. difference optional field targetDataType, value numeric variables set integer. read_dataset_json() write_dataset_json() rely fields must set properly. comes assumption requirements. Numeric dates converted type Date (see help(\"Date\", package=\"base\")) Numeric times converted {hms} type hms R doesn’t specific built type time. decided take {hms} dependency given type using {haven} package reading SAS Version 5 Transport files. , similar behavior can expected importing XPT Dataset JSON file. Numeric date times converted base R type POSIXct anchored UTC timezone. CDISC dates generally timezone qualified, though character dates, optional. Unless timezone explicitly specified systems may default user’s current timezone. decrease ambiguity, ’ve introduced hard requirement datetimes anchored UTC. datetime variable found using different timezone, error thrown. assumption don’t work purpose find situations need handle, please leave issue Github want make sure support community best can.","code":""},{"path":"https://atorus-research.github.io/datasetjson/articles/odm_details.html","id":"fileoid","dir":"Articles","previous_headings":"","what":"fileOID","title":"Notes on ODM V2","text":"FileOIDs universally unique possible. One way ensure prefix every FileOID internet domain name owned creator ODM file database (followed forward slash, “/”). example, FileOID=“BestPharmaceuticals.com/Study5894/1” might good way denote first file series study 5894 Best Pharmaceuticals. Reference link","code":""},{"path":"https://atorus-research.github.io/datasetjson/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Mike Stackhouse. Author, maintainer. Nicholas Masel. Author.","code":""},{"path":"https://atorus-research.github.io/datasetjson/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Stackhouse M, Masel N (2025). datasetjson: Read Write CDISC Dataset JSON Files. R package version 0.3.0, https://atorus-research.github.io/datasetjson/.","code":"@Manual{,   title = {datasetjson: Read and Write CDISC Dataset JSON Files},   author = {Mike Stackhouse and Nicholas Masel},   year = {2025},   note = {R package version 0.3.0},   url = {https://atorus-research.github.io/datasetjson/}, }"},{"path":"https://atorus-research.github.io/datasetjson/index.html","id":"datasetjson-","dir":"","previous_headings":"","what":"Read and Write CDISC Dataset JSON Files","title":"Read and Write CDISC Dataset JSON Files","text":"Welcome datasetjson. datasetjson R package built read write CDISC Dataset JSON formatted datasets. ’re stumbling world Dataset JSON, might wondering “JSON?”, many asked question. highly recommend take pit stop read blog post Sam Hume one creators Dataset JSON standard. always, welcome feedback. spot bug, like see new feature, documentation unclear - submit issue GitHub right .","code":""},{"path":"https://atorus-research.github.io/datasetjson/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Read and Write CDISC Dataset JSON Files","text":"can install datasetjson :","code":"# Install from CRAN: install.packages(\"datasetjson\")  # Or install the development version: devtools::install_github(\"https://github.com/atorus-research/datasetjson.git\", ref=\"dev\")"},{"path":"https://atorus-research.github.io/datasetjson/index.html","id":"using-datasetjson","dir":"","previous_headings":"","what":"Using datasetjson","title":"Read and Write CDISC Dataset JSON Files","text":"datasetjson works allowing take data frame apply necessary attributes required CDISC Dataset JSON. goal make experience simple. can write Dataset JSON file disk, first need build Dataset JSON object. example call looks like : attach necessary metadata (can’t inferred input dataframe time write) datasetjson object, can use variety setter functions: datasetjson object prepared necessary metadata, can use write_dataset_json() write file disk. don’t provide file path, JSON text return directly. read Dataset JSON file, can use read_dataset_json(). can either provide path JSON file, already JSON text loaded character string, can provide directly. data frame ’s returned enriched attributes available Dataset JSON format. example, opening dataframe within RStudio IDE present variable labels. metadata contained within Dataset JSON file attached attributes resulting dataframe. package currently supports Dataset JSON Version 1.1.0. Support Version 1.0.0 dropped, version 1.1.0 intended first stable version standard.","code":"ds_json <- dataset_json(   head(iris, 5),   file_oid = \"/some/path\",   last_modified = \"2023-02-15T10:23:15\",   originator = \"Some Org\",   sys = \"source system\",   sys_version = \"1.0\",   study = \"SOMESTUDY\",   metadata_version = \"MDV.MSGv2.0.SDTMIG.3.3.SDTM.1.7\",   metadata_ref = \"some/define.xml\",   item_oid = \"IG.IRIS\",   name = \"IRIS\",   dataset_label = \"Iris\",   columns = iris_items ) ds_json <- dataset_json(     head(iris, 5),     item_oid = \"IG.IRIS\",     name = \"IRIS\",     dataset_label = \"Iris\",     columns = iris_items   ) |>   set_file_oid(\"/some/path\") |>   set_last_modified(\"2025-01-21T13:34:50\") |>   set_originator(\"Some Org\") |>   set_source_system(\"source system\", \"1.0\") |>   set_study_oid(\"SOMESTUDY\") |>   set_metadata_ref(\"some/define.xml\") |>   set_metadata_version(\"MDV.MSGv2.0.SDTMIG.3.3.SDTM.1.7\") write_dataset_json(ds_json, file = \"./iris.json\") js_text <- write_dataset_json(ds_json, pretty=TRUE) cat(js_text) ## { ##   \"datasetJSONCreationDateTime\": \"2025-01-27T16:45:36\", ##   \"datasetJSONVersion\": \"1.1.0\", ##   \"fileOID\": \"/some/path\", ##   \"dbLastModifiedDateTime\": \"2025-01-21T13:34:50\", ##   \"originator\": \"Some Org\", ##   \"sourceSystem\": { ##     \"name\": \"source system\", ##     \"version\": \"1.0\" ##   }, ##   \"studyOID\": \"SOMESTUDY\", ##   \"metaDataVersionOID\": \"MDV.MSGv2.0.SDTMIG.3.3.SDTM.1.7\", ##   \"metaDataRef\": \"some/define.xml\", ##   \"itemGroupOID\": \"IG.IRIS\", ##   \"records\": 5, ##   \"name\": \"IRIS\", ##   \"label\": \"Iris\", ##   \"columns\": [ ##     { ##       \"itemOID\": \"IT.IR.Sepal.Length\", ##       \"name\": \"Sepal.Length\", ##       \"label\": \"Sepal Length\", ##       \"dataType\": \"float\", ##       \"keySequence\": 2 ##     }, ##     { ##       \"itemOID\": \"IT.IR.Sepal.Width\", ##       \"name\": \"Sepal.Width\", ##       \"label\": \"Sepal Width\", ##       \"dataType\": \"float\" ##     }, ##     { ##       \"itemOID\": \"IT.IR.Petal.Length\", ##       \"name\": \"Petal.Length\", ##       \"label\": \"Petal Length\", ##       \"dataType\": \"float\", ##       \"keySequence\": 3 ##     }, ##     { ##       \"itemOID\": \"IT.IR.Petal.Width\", ##       \"name\": \"Petal.Width\", ##       \"label\": \"Petal Width\", ##       \"dataType\": \"float\" ##     }, ##     { ##       \"itemOID\": \"IT.IR.Species\", ##       \"name\": \"Species\", ##       \"label\": \"Flower Species\", ##       \"dataType\": \"string\", ##       \"length\": 10, ##       \"keySequence\": 1 ##     } ##   ], ##   \"rows\": [ ##     [ ##       5.1, ##       3.5, ##       1.4, ##       0.2, ##       \"setosa\" ##     ], ##     [ ##       4.9, ##       3.0, ##       1.4, ##       0.2, ##       \"setosa\" ##     ], ##     [ ##       4.7, ##       3.2, ##       1.3, ##       0.2, ##       \"setosa\" ##     ], ##     [ ##       4.6, ##       3.1, ##       1.5, ##       0.2, ##       \"setosa\" ##     ], ##     [ ##       5.0, ##       3.6, ##       1.4, ##       0.2, ##       \"setosa\" ##     ] ##   ] ## } dat <- read_dataset_json(js_text) dat ##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1          5.1         3.5          1.4         0.2  setosa ## 2          4.9         3.0          1.4         0.2  setosa ## 3          4.7         3.2          1.3         0.2  setosa ## 4          4.6         3.1          1.5         0.2  setosa ## 5          5.0         3.6          1.4         0.2  setosa print(attr(dat, 'dbLastModifiedDateTime')) ## [1] \"2025-01-21T13:34:50\" print(attr(dat, 'fileOID')) ## [1] \"/some/path\""},{"path":[]},{"path":"https://atorus-research.github.io/datasetjson/index.html","id":"acknowledgements","dir":"","previous_headings":"","what":"Acknowledgements","title":"Read and Write CDISC Dataset JSON Files","text":"Thank Ben Straub Eric Simms (GSK) help input original CDISC Dataset JSON hackathon motivated work.","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/dataset_json.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Dataset JSON Object — dataset_json","title":"Create a Dataset JSON Object — dataset_json","text":"Create base object used write Dataset JSON file.","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/dataset_json.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Dataset JSON Object — dataset_json","text":"","code":"dataset_json(   .data,   file_oid = NULL,   last_modified = NULL,   originator = NULL,   sys = NULL,   sys_version = NULL,   study = NULL,   metadata_version = NULL,   metadata_ref = NULL,   item_oid = NULL,   name = NULL,   dataset_label = NULL,   columns = NULL,   version = \"1.1.0\" )"},{"path":"https://atorus-research.github.io/datasetjson/reference/dataset_json.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Dataset JSON Object — dataset_json","text":".data Input data contain within Dataset JSON file. Written itemData parameter. file_oid fileOID parameter, defined \"unique identifier file.\" (optional) last_modified date/time source database last modified creating Dataset-JSON file (optional) originator originator parameter, defined \"organization generated Dataset-JSON file.\" (optional) sys sourceSystem.name parameter, defined \"computer system database management system source information file.\" (Optional, required coupled sys_version) sys_version sourceSystem.Version, defined \"version sourceSystem\" (Optional, required coupled sys) study Study OID value (optional) metadata_version Metadata version OID value (optional) metadata_ref Metadata reference (.e. path Define.xml) (optional) item_oid ID used label dataset itemGroupData parameter. Defined \"Object Datasets. Key value unique identifier Dataset, corresponding ItemGroupDef/@OID Define-XML.\" name Dataset name dataset_label Dataset Label columns Variable level metadata Dataset JSON object. See details format requirements. version DatasetJSON version use. Currently 1.1.0 supported.","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/dataset_json.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Dataset JSON Object — dataset_json","text":"dataset_json object pertaining specific Dataset JSON version specific","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/dataset_json.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Dataset JSON Object — dataset_json","text":"columns parameter provided dataframe based Dataset JSON Specification: itemOID: string, required: Unique identifier variable may also function foreign key ItemDef/@OID associated Define-XML file. See ODM specification OID considerations. name: string, required: Variable name label: string, required: Variable label dataType: string, required: Logical data type variable. dataType attribute represents planned specificity data. See ODM Data Formats specification details. -targetDataType: string, optional: Indicates data type receiving system must transform associated Dataset-JSON variable. variable data type attribute dataType must converted targetDataType transforming Dataset-JSON dataset format operational use (e.g., SAS dataset, R dataframe, loading system's data store). specify targetDataType different dataType attribute JSON data type data needs transformed receiving system. See Supported Column Data Type Combinations table details usage. See User's Guide additional information. length: integer, optional: Specifies number characters allowed variable value represented text. displayFormat: *string, optional: SAS display format value used data visualization numeric float date values. keySequence: integer, optional: Indicates item key variable dataset structure. also provides ordering keys. Note DatasetJSON version 1.1.0. Based findings pilot, version 1.1.0 reflects feedback user community. Support 1.0.0 deprecated.","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/dataset_json.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Dataset JSON Object — dataset_json","text":"","code":"# Create a basic object ds_json <- dataset_json(   iris,   file_oid = \"/some/path\",   last_modified = \"2023-02-15T10:23:15\",   originator = \"Some Org\",   sys = \"source system\",   sys_version = \"1.0\",   study = \"SOMESTUDY\",   metadata_version = \"MDV.MSGv2.0.SDTMIG.3.3.SDTM.1.7\",   metadata_ref = \"some/define.xml\",   item_oid = \"IG.IRIS\",   name = \"IRIS\",   dataset_label = \"Iris\",   columns = iris_items )  # Attach attributes directly ds_json <- dataset_json(iris, columns = iris_items) ds_json <- set_file_oid(ds_json, \"/some/path\") ds_json <- set_last_modified(ds_json, \"2025-01-21T13:34:50\") ds_json <- set_originator(ds_json, \"Some Org\") ds_json <- set_source_system(ds_json, \"source system\", \"1.0\") ds_json <- set_study_oid(ds_json, \"SOMESTUDY\") ds_json <- set_metadata_ref(ds_json, \"some/define.xml\") ds_json <- set_metadata_version(ds_json, \"MDV.MSGv2.0.SDTMIG.3.3.SDTM.1.7\") ds_json <- set_item_oid(ds_json, \"IG.IRIS\") ds_json <- set_dataset_name(ds_json, \"Iris\") ds_json <- set_dataset_label(ds_json, \"The Iris Dataset\")"},{"path":"https://atorus-research.github.io/datasetjson/reference/dataset_metadata_setters.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset Metadata Setters — set_source_system","title":"Dataset Metadata Setters — set_source_system","text":"Set information file, source system, study, dataset used generate Dataset JSON object.","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/dataset_metadata_setters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset Metadata Setters — set_source_system","text":"","code":"set_source_system(x, sys, sys_version)  set_originator(x, originator)  set_file_oid(x, file_oid)  set_study_oid(x, study)  set_metadata_version(x, metadata_version)  set_metadata_ref(x, metadata_ref)  set_item_oid(x, item_oid)  set_dataset_name(x, name)  set_dataset_label(x, dataset_label)  set_last_modified(x, last_modified)"},{"path":"https://atorus-research.github.io/datasetjson/reference/dataset_metadata_setters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dataset Metadata Setters — set_source_system","text":"x datasetjson object sys sourceSystem.name parameter, defined \"computer system database management system source information file.\" (Optional, required coupled sys_version) sys_version sourceSystem.Version, defined \"version sourceSystem\" (Optional, required coupled sys) originator originator parameter, defined \"organization generated Dataset-JSON file.\" (optional) file_oid fileOID parameter, defined \"unique identifier file.\" (optional) study Study OID value (optional) metadata_version Metadata version OID value (optional) metadata_ref Metadata reference (.e. path Define.xml) (optional) item_oid ID used label dataset itemGroupData parameter. Defined \"Object Datasets. Key value unique identifier Dataset, corresponding ItemGroupDef/@OID Define-XML.\" name Dataset name dataset_label Dataset Label last_modified date/time source database last modified creating Dataset-JSON file (optional)","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/dataset_metadata_setters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dataset Metadata Setters — set_source_system","text":"datasetjson object","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/dataset_metadata_setters.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dataset Metadata Setters — set_source_system","text":"fileOID parameter structured following description outlined ODM V2.0 specification. \"FileOIDs universally unique possible. One way ensure prefix every FileOID internet domain name owned creator ODM file database (followed forward slash, \"/\"). example, FileOID=\"BestPharmaceuticals.com/Study5894/1\" might good way denote first file series study 5894 Best Pharmaceuticals.\"","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/dataset_metadata_setters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dataset Metadata Setters — set_source_system","text":"","code":"ds_json <- dataset_json(iris, columns = iris_items) ds_json <- set_file_oid(ds_json, \"/some/path\") ds_json <- set_last_modified(ds_json, \"2025-01-21T13:34:50\") ds_json <- set_originator(ds_json, \"Some Org\") ds_json <- set_source_system(ds_json, \"source system\", \"1.0\") ds_json <- set_study_oid(ds_json, \"SOMESTUDY\") ds_json <- set_metadata_ref(ds_json, \"some/define.xml\") ds_json <- set_metadata_version(ds_json, \"MDV.MSGv2.0.SDTMIG.3.3.SDTM.1.7\") ds_json <- set_item_oid(ds_json, \"IG.IRIS\") ds_json <- set_dataset_name(ds_json, \"Iris\") ds_json <- set_dataset_label(ds_json, \"The Iris Dataset\")"},{"path":"https://atorus-research.github.io/datasetjson/reference/datasetjson-package.html","id":null,"dir":"Reference","previous_headings":"","what":"datasetjson: Read and Write CDISC Dataset JSON Files — datasetjson-package","title":"datasetjson: Read and Write CDISC Dataset JSON Files — datasetjson-package","text":"Read, construct write CDISC (Clinical Data Interchange Standards Consortium) Dataset JSON (JavaScript Object Notation) files, validating per Dataset JSON schema file, described CDISC (2023) https://www.cdisc.org/standards/data-exchange/dataset-json.","code":""},{"path":[]},{"path":"https://atorus-research.github.io/datasetjson/reference/datasetjson-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"datasetjson: Read and Write CDISC Dataset JSON Files — datasetjson-package","text":"Maintainer: Mike Stackhouse mike.stackhouse@atorusresearch.com (ORCID) Authors: Nicholas Masel nmasel@.jnj.com","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/get_column_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract column metadata to data frame — get_column_metadata","title":"Extract column metadata to data frame — get_column_metadata","text":"function pulls column metadata datasetjson object attributes user-friendly data.frame.","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/get_column_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract column metadata to data frame — get_column_metadata","text":"","code":"get_column_metadata(x)"},{"path":"https://atorus-research.github.io/datasetjson/reference/get_column_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract column metadata to data frame — get_column_metadata","text":"x datasetjson object","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/get_column_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract column metadata to data frame — get_column_metadata","text":"data frame containing columns metadata","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/get_column_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract column metadata to data frame — get_column_metadata","text":"","code":"ds_json <- dataset_json(   iris,   item_oid = \"IG.IRIS\",   name = \"IRIS\",   dataset_label = \"Iris\",   columns = iris_items )  get_column_metadata(ds_json) #>              itemOID         name          label dataType keySequence #> 1 IT.IR.Sepal.Length Sepal.Length   Sepal Length    float           2 #> 2  IT.IR.Sepal.Width  Sepal.Width    Sepal Width    float          NA #> 3 IT.IR.Petal.Length Petal.Length   Petal Length    float           3 #> 4  IT.IR.Petal.Width  Petal.Width    Petal Width    float          NA #> 5      IT.IR.Species      Species Flower Species   string           1 #>   targetDataType length displayFormat #> 1           <NA>     NA          <NA> #> 2           <NA>     NA          <NA> #> 3           <NA>     NA          <NA> #> 4           <NA>     NA          <NA> #> 5           <NA>     10          <NA>"},{"path":"https://atorus-research.github.io/datasetjson/reference/iris_items.html","id":null,"dir":"Reference","previous_headings":"","what":"Example Variable Metadata for Iris — iris_items","title":"Example Variable Metadata for Iris — iris_items","text":"Example necessary variable metadata included Dataset JSON file based Iris data frame.","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/iris_items.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example Variable Metadata for Iris — iris_items","text":"","code":"iris_items"},{"path":[]},{"path":"https://atorus-research.github.io/datasetjson/reference/iris_items.html","id":"iris-items-a-data-frame-with-rows-and-columns-","dir":"Reference","previous_headings":"","what":"iris_items A data frame with 5 rows and 6 columns:","title":"Example Variable Metadata for Iris — iris_items","text":"itemOID Unique identifier Variable. Must correspond ItemDef/@OID Define-XML. name Display format supports data visualization numeric float date values. label Label Variable dataType Data type Variable length Length Variable keySequence Indicates item key variable dataset structure. also provides ordering keys.","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/read_dataset_json.html","id":null,"dir":"Reference","previous_headings":"","what":"Read a Dataset JSON to datasetjson object — read_dataset_json","title":"Read a Dataset JSON to datasetjson object — read_dataset_json","text":"function validates dataset JSON file Dataset JSON schema, valid returns datasetjson object. Dataset JSON file can either file path disk URL contains Dataset JSON file.","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/read_dataset_json.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read a Dataset JSON to datasetjson object — read_dataset_json","text":"","code":"read_dataset_json(file, decimals_as_floats = FALSE)"},{"path":"https://atorus-research.github.io/datasetjson/reference/read_dataset_json.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read a Dataset JSON to datasetjson object — read_dataset_json","text":"file File path URL Dataset JSON file decimals_as_floats Convert variables \"decimal\" type float","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/read_dataset_json.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read a Dataset JSON to datasetjson object — read_dataset_json","text":"dataframe additional attributes attached containing DatasetJSON metadata.","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/read_dataset_json.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read a Dataset JSON to datasetjson object — read_dataset_json","text":"resulting dataframe contains additional metadata available Dataset JSON file within attributes make accessible user. Note attributes populated available. sourceSystem: information system content dataset source, including system name version. datasetJSONVersion: version Dataset-JSON standard used create dataset. fileOID: unique identifier dataset. dbLastModifiedDateTime: date/time source database last modified creating Dataset-JSON file. originator: organization generated Dataset-JSON dataset. studyOID: Unique identifier study may also function foreign key Study/@OID associated Define-XML document, studyOID references used keys documents; metaDataVersionOID: Unique identifier metadata version may also function foreign key MetaDataVersion/@OID associated Define-XML file metaDataRef: URI metadata file describing dataset (e.g., Define-XML file). itemGroupOID: Unique identifier dataset may also function foreign key ItemGroupDef/@OID associated Define-XML file. name: human-readable name dataset. label: short description dataset. columns: array metadata objects describe dataset variables. See dataset_json() information contents fields.","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/read_dataset_json.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read a Dataset JSON to datasetjson object — read_dataset_json","text":"","code":"# Read from disk if (FALSE) { # \\dontrun{   dat <- read_dataset_json(\"path/to/file.json\")  # Read file from URL   dat <- dataset_json('https://www.somesite.com/file.json') } # }  # Read from an already imported character vector ds_json <- dataset_json(iris, \"IG.IRIS\", \"IRIS\", \"Iris\", columns=iris_items) js <- write_dataset_json(ds_json) dat <- read_dataset_json(js)"},{"path":"https://atorus-research.github.io/datasetjson/reference/schema_1_1_0.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset JSON Schema Version 1.1.0 — schema_1_1_0","title":"Dataset JSON Schema Version 1.1.0 — schema_1_1_0","text":"object character vector holding schema Dataset JSON Version 1.1.0","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/schema_1_1_0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset JSON Schema Version 1.1.0 — schema_1_1_0","text":"","code":"schema_1_1_0"},{"path":[]},{"path":[]},{"path":"https://atorus-research.github.io/datasetjson/reference/set_variable_attributes.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign Dataset JSON attributes to data frame columns — set_variable_attributes","title":"Assign Dataset JSON attributes to data frame columns — set_variable_attributes","text":"Using columns element Dataset JSON file, assign available metadata individual columns","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/set_variable_attributes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign Dataset JSON attributes to data frame columns — set_variable_attributes","text":"","code":"set_variable_attributes(x)"},{"path":"https://atorus-research.github.io/datasetjson/reference/set_variable_attributes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign Dataset JSON attributes to data frame columns — set_variable_attributes","text":"x datasetjson object","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/set_variable_attributes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assign Dataset JSON attributes to data frame columns — set_variable_attributes","text":"datasetjson object attributes assigned individual variables","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/set_variable_attributes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign Dataset JSON attributes to data frame columns — set_variable_attributes","text":"","code":"ds_json <- dataset_json(   iris,   item_oid = \"IG.IRIS\",   name = \"IRIS\",   dataset_label = \"Iris\",   columns = iris_items )  ds_json <- set_variable_attributes(ds_json)"},{"path":"https://atorus-research.github.io/datasetjson/reference/validate_dataset_json.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate a Dataset JSON file — validate_dataset_json","title":"Validate a Dataset JSON file — validate_dataset_json","text":"function calls jsonvalidate::json_validate() directly, parameters necessary retrieve error information invalid JSON file per Dataset JSON schema.","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/validate_dataset_json.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate a Dataset JSON file — validate_dataset_json","text":"","code":"validate_dataset_json(x)"},{"path":"https://atorus-research.github.io/datasetjson/reference/validate_dataset_json.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate a Dataset JSON file — validate_dataset_json","text":"x File path URL Dataset JSON file, character vector holding JSON text","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/validate_dataset_json.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate a Dataset JSON file — validate_dataset_json","text":"data frame","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/validate_dataset_json.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate a Dataset JSON file — validate_dataset_json","text":"","code":"if (FALSE) { # \\dontrun{   validate_dataset_json('path/to/file.json')   validate_dataset_json('https://www.somesite.com/file.json') } # }  ds_json <- dataset_json(   iris,   item_oid = \"IG.IRIS\",   name = \"IRIS\",   dataset_label = \"Iris\",   columns = iris_items ) js <- write_dataset_json(ds_json)  validate_dataset_json(js) #> File is valid per the Dataset JSON v1.1.0 schema #> [1] instancePath schemaPath   keyword      params       message      #> [6] schema       parentSchema dataPath     #> <0 rows> (or 0-length row.names)"},{"path":"https://atorus-research.github.io/datasetjson/reference/write_dataset_json.html","id":null,"dir":"Reference","previous_headings":"","what":"Write out a Dataset JSON file — write_dataset_json","title":"Write out a Dataset JSON file — write_dataset_json","text":"Write Dataset JSON file","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/write_dataset_json.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write out a Dataset JSON file — write_dataset_json","text":"","code":"write_dataset_json(   x,   file,   pretty = FALSE,   float_as_decimals = FALSE,   digits = 16 )"},{"path":"https://atorus-research.github.io/datasetjson/reference/write_dataset_json.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write out a Dataset JSON file — write_dataset_json","text":"x datasetjson object file File path save Dataset JSON file pretty TRUE, write readable formatting. Note: Dataset JSON standard prefers compressed formatting without line feeds. recommended use pretty printing submission purposes. float_as_decimals TRUE, Convert float variables \"decimal\" data type JSON output. manually convert numeric values using format() function using number digits specified digits, bypassing yyjsonr handling float values writing numbers JSON character strings. See Dataset JSON user guide information. Defaults FALSE digits using float_as_decimals, number digits use writing floats. Going higher 16 may start writing otherwise sufficiently precise decimals (.e. .2) long strings.","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/write_dataset_json.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write out a Dataset JSON file — write_dataset_json","text":"NULL file written disk, otherwise character string","code":""},{"path":"https://atorus-research.github.io/datasetjson/reference/write_dataset_json.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write out a Dataset JSON file — write_dataset_json","text":"","code":"# Write to character object ds_json <- dataset_json(   iris,   item_oid = \"IG.IRIS\",   name = \"IRIS\",   dataset_label = \"Iris\",   columns = iris_items ) js <- write_dataset_json(ds_json)  # Write to disk if (FALSE) { # \\dontrun{   write_dataset_json(ds_json, \"path/to/file.json\") } # }"}]
